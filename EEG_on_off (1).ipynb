{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Todo\n",
        "1. fix plotting graph error\n",
        "2. get the data\n",
        "  - calculate the data needed for each time try to balance both ofthe on and off\n",
        "3. test the model and adjust the model layers\n",
        "5. create an app that automtically preprocess the data\n",
        "  - Select between SMOTE and RandomOverSampler\n",
        "  - modifying the Layers\n",
        "    - dropoff selection\n",
        "    - LSTM vs GRU\n",
        "    - modify the amount of node used in each layer\n",
        "      - if it overfitting decrease the node\n",
        "      - if it underfitting increase the node\n",
        "6. add the model analysis graph at the end of the training\n"
      ],
      "metadata": {
        "id": "DNomBjwhphiw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For real time EEG use (if we already have a trained model)\n",
        "\n",
        "1. real time Data acquisition\n",
        "2. Data Preprocessing Pipeline\n",
        "3. Main Real time Loop"
      ],
      "metadata": {
        "id": "AQRDy2sUGab-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's set up and load some file"
      ],
      "metadata": {
        "id": "M29LGkovHzd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imblearn"
      ],
      "metadata": {
        "id": "y58T2HK_JQi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import library section\n",
        "from zipfile import ZipFile\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, ReLU, MaxPool1D, LSTM, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n"
      ],
      "metadata": {
        "id": "1CQ9xmciqWgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "iRSEEuCpWri1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYXKSpPxHtIr"
      },
      "outputs": [],
      "source": [
        "# add the file path here\n",
        "filepath = \"/content/drive/MyDrive/EEG_on_off/.csv.zip\"\n",
        "extract_path = \"/content/drive/MyDrive/EEG_on_off/\"\n",
        "with ZipFile(filepath, \"r\") as zip:\n",
        "    zip.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# I think the information we are going to collect and use is in the full file from\n",
        "# but I think we are going to think on one file and think off one file\n",
        "# and then came here and label everything in those file\n",
        "# on or off or set it as 0, 1\n",
        "on_path = \"\"\n",
        "off_path = \"\"\n",
        "\n",
        "on_data = pd.read_csv(on_path)\n",
        "off_data = pd.read_csv(off_path)"
      ],
      "metadata": {
        "id": "ZY6lEV6EIO0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Exploration"
      ],
      "metadata": {
        "id": "wX7W-FBuqqxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape_on = on_data.shape\n",
        "shape_off = off_data.shape\n",
        "\n",
        "print(shape_on)\n",
        "print(shape_off)"
      ],
      "metadata": {
        "id": "1_FxmXqFRo7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "add label to both of the data"
      ],
      "metadata": {
        "id": "PYFViRPJqxN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: add a label column to on and off dataframe\n",
        "\n",
        "on_data['label'] = 1  # Label 'on' data with 1\n",
        "off_data['label'] = 0 # Label 'off' data with 0"
      ],
      "metadata": {
        "id": "e9XamZDsSEJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(on_data.describe())\n",
        "display(off_data.describe())"
      ],
      "metadata": {
        "id": "KszvzsvoTomm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "on_data.head()"
      ],
      "metadata": {
        "id": "t8ZkziO5I_pM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "off_data.head()"
      ],
      "metadata": {
        "id": "87rUWZG7JARI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "on_data.info()\n",
        "off_data.info()"
      ],
      "metadata": {
        "id": "NqsIUmnFR7Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare Sample data\n",
        "\n"
      ],
      "metadata": {
        "id": "yJccpH1qrghc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "!!! Don't forget to change the sequence length here\n",
        "\"\"\"\n",
        "\n",
        "# let's select some random sample\n",
        "n = np.random.randint(100)\n",
        "seq_len = 2549\n",
        "\n",
        "# .iloc[row, column]\n",
        "# see some random eeg data\n",
        "on_eeg = on_data.iloc[n, :seq_len]\n",
        "off_eeg = off_data.iloc[n, :seq_len]\n",
        "\n",
        "plt.plot(on_eeg, label=\"on\")\n",
        "plt.plot(off_eeg, label=\"off\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uxyNJyFhJ8bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Entire data"
      ],
      "metadata": {
        "id": "MwGVMpsbrzkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# now let's see all of the data in the graph to see the overall different\n",
        "plt.figure(figsize=(16,10), dpi=200)\n",
        "# plot 2 rows 1 column at position 1\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(on_data.iloc[:, :seq_len], label=\"on\")\n",
        "plt.title(\"On\")\n",
        "plt.legend()\n",
        "\n",
        "# plot 2 rows 1 column at position 2\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.title(\"Off\")\n",
        "plt.plot(off_data.iloc[:, :seq_len], label=\"off\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0hYCFBhOMCM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine both data frame"
      ],
      "metadata": {
        "id": "llMJWyEmJHoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: label every thing in those two dataframe with 0 mean off and 1 mean on, and then join those two dataframe (join in vertical though like adding more data)\n",
        "\n",
        "# Label the dataframes\n",
        "on_data['label'] = 1\n",
        "off_data['label'] = 0\n",
        "\n",
        "# Combine the dataframes vertically\n",
        "# so now I join with ignore index so the the index won't combine with each other\n",
        "combined_data = pd.concat([on_data, off_data], ignore_index=True)\n",
        "\n",
        "# let's check the head and the tail of the data\n",
        "print(combined_data.head())\n",
        "print(combined_data.tail())\n",
        "combined_data.shape\n"
      ],
      "metadata": {
        "id": "uYrtBPpzOUZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data.info()"
      ],
      "metadata": {
        "id": "b43_Dps3R0qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check Null data\n"
      ],
      "metadata": {
        "id": "w4YVRh9LSA8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# display the max columns (the column with the most NULL)\n",
        "\n",
        "pd.set_option('display.max_column', None)\n",
        "on_data.isnull().sum()\n",
        "off_data.isnull().sum()"
      ],
      "metadata": {
        "id": "q1KIXYWzSAJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check Each type of the Sample\n"
      ],
      "metadata": {
        "id": "0la6Fj32PuJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "on_eeg = combined_data.loc[combined_data['label'] == 1, :].iloc[:, :seq_len]\n",
        "off_eeg = combined_data.loc[combined_data['label'] == 0, :].iloc[:, :seq_len]\n",
        "\n",
        "plt.figure(figsize=(16,10), dpi=200)\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(on_eeg.T, label=\"on\") # Use .T to plot each sample as a line\n",
        "plt.title(\"On\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(off_eeg.T, label=\"off\") # Use .T to plot each sample as a line\n",
        "plt.title(\"Off\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WBiYPfNKJPDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See the distribution of the data"
      ],
      "metadata": {
        "id": "PdY87n6BSzW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {\n",
        "    0: \"off\",\n",
        "    1: \"on\"\n",
        "}\n",
        "\n",
        "value_counts = combined_data.iloc[:,-1].value_counts().rename(labels)\n",
        "\n",
        "plt.bar(value_counts.index, value_counts.values)\n",
        "plt.xlabel(\"Label\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Labels\")\n",
        "plt.xticks(rotation=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qVS-QtcUSymR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "d42xrQleVlMF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmentation"
      ],
      "metadata": {
        "id": "Fy_PRDRLXvhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ros = RandomOverSampler(random_state=42)\n",
        "data = combined_data.iloc[:, :-1]\n",
        "labels = combined_data.iloc[:, -1]\n",
        "X_train_resampled, y_train_resampled = ros.fit_resample(data, labels)\n",
        "\n",
        "df = pd.concat([X_train_resampled, y_train_resampled], axis=1)\n",
        "# replave the old data frame with the same index (new dataframe)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "nHAM9bDLYGhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "x9YjQXldYt-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the data Distribution"
      ],
      "metadata": {
        "id": "egkspRnkY0Vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {\n",
        "    0: \"off\",\n",
        "    1: \"on\"\n",
        "}\n",
        "\n",
        "value_counts = df.iloc[:,-1].value_counts().rename(labels)\n",
        "\n",
        "plt.bar(value_counts.index, value_counts.values)\n",
        "plt.xlabel(\"Label\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Labels\")\n",
        "plt.xticks(rotation=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Qh6j3V5bYzxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Test Split"
      ],
      "metadata": {
        "id": "QWuwkpUlVqS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "we can adjust the split of the data here if we want to see the difference\n",
        "\"\"\"\n",
        "\n",
        "train, temp = train_test_split(df, test_size=0.4, random_state=42)\n",
        "val, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
        "\n",
        "train.shape()\n",
        "test.shape()\n",
        "val.shape()"
      ],
      "metadata": {
        "id": "3C7aCBppVzPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split Label and Feature"
      ],
      "metadata": {
        "id": "rbttgMwzXLCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.iloc[:, :-1]\n",
        "y_train = train.iloc[:, -1]\n",
        "\n",
        "X_test = test.iloc[:, :-1]\n",
        "y_test = test.iloc[:, -1]\n",
        "\n",
        "X_val = val.iloc[:, :-1]\n",
        "y_val = val.iloc[:, -1]\n",
        "\n",
        "X_train.shape()\n",
        "y_train.shape()\n",
        "X_test.shape()\n",
        "y_test.shape()\n",
        "X_val.shape()\n",
        "y_val.shape()"
      ],
      "metadata": {
        "id": "BC6IpmDzXKSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Reshape"
      ],
      "metadata": {
        "id": "bTGIrFCGIVtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# just like the same shpae but add the make the voltage value into array for future feature to came in\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
        "\n",
        "X_train.shape()\n",
        "X_test.shape()\n",
        "X_val.shape()"
      ],
      "metadata": {
        "id": "MwmjiJfCIikR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Don't need to run this. but in the future we maybe have to run this\n",
        "because now our output is just 0,1\n",
        "but later we maybe want to convert it to array\n",
        "\"\"\"\n",
        "classification_num = 2 # on off\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=2)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes=2)\n"
      ],
      "metadata": {
        "id": "IsG8Q635IVVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the model"
      ],
      "metadata": {
        "id": "ChcC7Ympbdsp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I want the model to be something like this\n",
        "\n",
        "\"Let try a lot of combination we still got sometime\"\n",
        "Input layer\n",
        "1. 1D CNN layers x3 (32, 74, 128)\n",
        "  - BatchNormalization\n",
        "  - ReLU()\n",
        "  - Maxpool1D\n",
        "2. LSTM layer (1-2 layer would be good)\n",
        "  - 64 - 128 units\n",
        "3. Dense layer\n",
        "  - 64 ReLu\n",
        "  - 32 ReLu\n",
        "  - 1 Sigmoid\n"
      ],
      "metadata": {
        "id": "ucwtlEXTKaBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_on_off = Sequential([\n",
        "    Input(shape=(X_train.shape[1:])),\n",
        "\n",
        "    Conv1D(32, 5, padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    ReLU(),\n",
        "    MaxPool1D(pool_size=2),\n",
        "    Dropout(0.1),\n",
        "\n",
        "    Conv1D(64, 5, padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    ReLU(),\n",
        "    MaxPool1D(pool_size=2),\n",
        "    Dropout(0.15),\n",
        "\n",
        "    Conv1D(128, 5, padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    ReLU(),\n",
        "    MaxPool1D(pool_size=2),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, activation=\"tanh\"),\n",
        "    LSTM(32, dropout=0.2, recurrent_dropout=0.2, activation=\"tanh\"),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    Dropout(0.4),\n",
        "    Dense(32, activation=\"relu\"),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation=\"sigmoid\") # Changed activation to sigmoid for binary classification\n",
        "    # if we want to add more function I might have to use the softmax (later adjustment)\n",
        "])\n",
        "\n",
        "model_on_off.summary()"
      ],
      "metadata": {
        "id": "06gVq4jUMD0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile the model"
      ],
      "metadata": {
        "id": "MdLRteiWPi40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_on_off.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "utL6X-7APlwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Callbacks"
      ],
      "metadata": {
        "id": "JkyTYkkRQEIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [EarlyStopping(monitor='val_loss', patience=8),\n",
        "             ReduceLROnPlateau(\n",
        "                 patience=20,\n",
        "                 monitor='val_loss',\n",
        "                 min_lr=1e-5,\n",
        "                 cool_down=20),\n",
        "              ModelCheckpoint('best_model.h5',\n",
        "                              save_best_only=True,\n",
        "                              monitor='val_loss')\n",
        "              ]"
      ],
      "metadata": {
        "id": "ISbcAHejQDYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_on_off.fit(X_train, y_train,\n",
        "                           validation_data=(X_val, y_val),\n",
        "                           epochs=10,\n",
        "                           batch_size=32,\n",
        "                           callbacks=callbacks,\n",
        "                           verbose=1)"
      ],
      "metadata": {
        "id": "3Qc0eOkQQ8ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3672982"
      },
      "source": [
        "# Save the model\n",
        "model_on_off.save('/content/drive/MyDrive/my_models/my_eeg_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Access Model and use model"
      ],
      "metadata": {
        "id": "UD_lgNUeoDrA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a5a0222"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/my_models/my_eeg_model.h5')\n",
        "\n",
        "# Display the model summary to confirm it's loaded correctly\n",
        "loaded_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So to use this model when attaching to the EEG measure tool I need to made an app that autometically preprocess the data like process before making the model"
      ],
      "metadata": {
        "id": "abGtGdnOo5Pc"
      }
    }
  ]
}